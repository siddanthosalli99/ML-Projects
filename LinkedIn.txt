Wrapped Up My First Year + 8 Machine Learning Projects!

As I just completed my freshman year at IIIT Kottayam, I spent my summer break diving deep into applied machine learning â€” 
and Iâ€™m thrilled to share that Iâ€™ve completed 8 end-to-end projects!
Now stepping into my sophomore year, Iâ€™m more motivated than ever to keep learning and building.

ðŸ“‚ Supervised Learning Projects:
âœ… Classification (3 real-world projects)
âœ… Regression (3 real-world projects)

ðŸ“‚ Unsupervised Learning Projects:
âœ… Clustering (2 Projects)

Throughout this process, Iâ€™ve learned all the major concepts of feature engineering (missing values, encoding, scaling, outliers, etc.) and gained a solid understanding 
of the working of the most frequently used and important ML algorithms like 
Logistic Regression, Linear Regression, SVM, Decision Trees, Random Forest, Ensemble Learning, XGBoost, DBSCAN and more.

I used real-world datasets from Kaggle, handled missing values, outliers, scaling, and feature engineering â€” and applied models like 
Logistic Regression, SVM, Random Forest, XGBoost, and DBSCAN.

To fine-tune performance, I explored Optuna for hyperparameter tuning and performance metrics for model evaluation.

Iâ€™ll be sharing screenshots from my hand-typed files along with this post to give a glimpse of the actual work Iâ€™ve done.
but if anyoneâ€™s interested in checking them out, feel free to let me know, I'd be glad to connect with people who share the same mindset and curiosity!

Tech Stack:
Python | Pandas | NumPy | Scikit-learn | Matplotlib | Seaborn | Optuna | XGBoost

ðŸ”— You can check out the projects on my GitHub:
ðŸ‘‰ [your GitHub link here]


#MachineLearning #DeepLearning #DataScience #MLProjects #Kaggle #Classification #Regression #Clustering #Python #XGBoost #Optuna #IIIT #OpenToWork 
#StudentProjects #FirstYearToSecondYear
